### model
model_name_or_path: YOUR_DIR/models/gemma-7b
adapter_name_or_path: YOUR_DIR/wmt_gemma7-factory-sft

### method
stage: sft
do_predict: true
finetuning_type: lora

### dataset
dataset: wmt
template: gemma
cutoff_len: 1024
overwrite_cache: true
preprocessing_num_workers: 16
dataset_dir: YOUR_DIR/STAFF/finetune/data
# max_samples: 32
tokenized_path: YOUR_DIR/STAFF/finetune/data/wmt_dataset_test-gemma-7b


### output
output_dir: YOUR_DIR/wmt_gemma7-factory-sft/predict
overwrite_output_dir: true

### eval
val_size: 0.1
per_device_eval_batch_size: 8
predict_with_generate: true
ddp_timeout: 180000000